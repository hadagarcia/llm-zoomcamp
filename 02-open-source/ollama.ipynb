{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da161e2-1b60-4e3a-8db3-6ba9db8608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [markdown]\n",
    "\n",
    "# # Using Ollama with OpenAI's API. \n",
    "# Llama3 model is running in docker container on localhost:11434, so it can be used locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f19d00-0d48-4129-9ef5-8623f0655c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# # Importing the libraries\n",
    "import requests, json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eafeed-5430-4214-b034-c1a3eb856707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Get the minsearch library\n",
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py'\n",
    "r = requests.get(url)\n",
    "# Assuming you want to save the content of the URL to a file named 'minsearch.py' in the current directory\n",
    "with open('minsearch.py', 'wb') as f:\n",
    "   f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfbc9a-953d-4ef6-b4d3-2f5263d8271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x22152f915e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Download the data\n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b3c77-c6f9-43cf-b05b-c8f3c5fd6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Define the search query\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af80e9-fa3d-4f0b-9a0e-27b453e5f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Define the build prompt method\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a214c4a-1131-44b3-9666-c40102ce972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Define OpenAI API client\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bdf5d-6d0d-43a3-9a4f-fccbc492bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Define the LLM api call\n",
    "\n",
    "def llm_llama3(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='llama3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def llm_phi3(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18715c74-a5ab-4d0b-aa09-86c9950f7c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**TEST**\\n\\nThis is only a test. Not real. Just a simulation to see if things are working properly. Don't worry, no actual consequences will result from this test... yet.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Test the LLM method\n",
    "llm_llama3('write that this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec6da1-58cf-421d-976a-8cfaa79bf437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's great that you're interested in the course!\\n\\nHowever, I'd like to clarify a few things. As our conversation began, it appears that we are not connected to any specific course or institution. If you could provide more context or details about the course you're interested in, such as its name, location, and any relevant deadlines, I'll do my best to help you determine if it's still possible for you to join.\\n\\nPlease share more information, and I'll assist you in exploring your options!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Ask Llama3 our question without finetuning.\n",
    "llm_llama3('I just found out about this course, can I still join?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef525e-a563-4f6b-971d-72f005524a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Define the RAG method\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_llama3(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a0293-6c3d-4bf0-b049-9c24fc8c2f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from Llama3 with finetuning: According to the FAQ database, even though you've found out about the course after the start date, yes, you can still join! The answer explicitly states that \"Yes, even if you don't register, you're still eligible to submit the homeworks.\" So, go ahead and register using this link, and get started on the course materials!\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Test the RAG method\n",
    "query = \"I just found out about this course, can I still join?\"\n",
    "print(f\"Answer from Llama3 with finetuning: {rag(query)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
