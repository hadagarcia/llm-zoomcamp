{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6640b9b4-cb53-4adb-828c-090f08bbaee2",
   "metadata": {},
   "source": [
    "#%% [markdown]\n",
    "\n",
    " # Homework\n",
    " Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599f66a-8160-4034-b700-55b2e5df4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "import tiktoken \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the data\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d60874-3cd0-44a6-9070-3020a204bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-1080d8d90135>:25: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=index_name, ignore=[400, 404])\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Index the data using elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "# First delete the index if it exists (if we want to avoid an error while running multiple times)\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    es_client.indices.delete(index=index_name, ignore=[400, 404])\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "for doc in documents:\n",
    "    es_client.index(index=index_name, body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950324ef-8103-4df0-b790-6eb0e448ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: Filter:[] - 84.050095\n",
      "\n",
      "Score: Filter:[] - 75.54128\n",
      "\n",
      "Score: Filter:[] - 72.08518\n",
      "\n",
      "Score: Filter:[] - 51.04628\n",
      "\n",
      "Score: Filter:[] - 49.938507\n",
      "\n",
      "Filtering by: machine-learning-zoomcamp\n",
      "Score: Filter:[machine-learning-zoomcamp] - 84.050095\n",
      "\n",
      "Score: Filter:[machine-learning-zoomcamp] - 51.04628\n",
      "\n",
      "Score: Filter:[machine-learning-zoomcamp] - 49.938507\n",
      "\n",
      "Score: Filter:[machine-learning-zoomcamp] - 45.275463\n",
      "\n",
      "Score: Filter:[machine-learning-zoomcamp] - 45.255775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Query using elasticsearch\n",
    "def elastic_search(query, filter=''):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"], #^4 to give priority to the question field\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if filter:\n",
    "        print(f\"Filtering by: {filter}\")\n",
    "        search_query['query']['bool']['filter'] = {\n",
    "            \"term\": {\n",
    "                \"course\": filter\n",
    "            }\n",
    "        }\n",
    "\n",
    "    es_response = es_client.search(index=index_name, body=search_query)\n",
    "    es_result_docs = []\n",
    "    \n",
    "    for hit in es_response['hits']['hits']:\n",
    "        es_result_docs.append(hit['_source'])\n",
    "        \n",
    "        # Homework: Q3 - Searching: score for top record\n",
    "        print(f\"Score: Filter:[{filter}] - {hit['_score']}\\n\")\n",
    "    \n",
    "    return es_result_docs\n",
    "\n",
    "query = \"How do I execute a command in a running docker container?\"\n",
    "filter = \"machine-learning-zoomcamp\"\n",
    "\n",
    "results_no_filter = elastic_search(query)\n",
    "\n",
    "# Homework: Q4 - Filtering\n",
    "results_filter = elastic_search(query, filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60083d2f-94a9-48e4-9301-ccd98485854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 2778\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Building a prompt\n",
    "\n",
    "def build_prompt(query, results):\n",
    "    \n",
    "    context = \"\"\n",
    "    context_template = \"\"\"\n",
    "        Q: {question}\n",
    "        A: {text} \\n\\n\n",
    "        \"\"\".strip()\n",
    "        \n",
    "    prompt_template = \"\"\"\n",
    "        You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "        Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "        QUESTION: {question}\n",
    "\n",
    "        CONTEXT:\n",
    "        {context}\n",
    "        \"\"\".strip()\n",
    "        \n",
    "    for doc in results:\n",
    "        context += context_template.format(question=doc['question'], text=doc['text'])\n",
    "        \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    \n",
    "    # Homework: Q5 - Prompt length\n",
    "    print(f\"Prompt length: {len(prompt)}\")\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "built_prompt = build_prompt(query, results_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e942c-49ae-4d69-9a88-dfc2369f0486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 628\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Calculating tokens for the prompt\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(built_prompt)\n",
    "\n",
    "# Homework: Q6 - Tokens\n",
    "print(f\"Tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8df5a5-40e0-4755-80ad-fc064b31d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 2778\n",
      "Question: How do I execute a command in a running docker container?\n",
      "Answer: To execute a command in a running Docker container, you first need to find the container ID. You can do this by running the command `docker ps`. Once you have the container ID, you can execute a command in the specific container using the `docker exec -it <container-id> bash` command. This will open an interactive bash shell in the running container where you can execute commands.\n"
     ]
    }
   ],
   "source": [
    "# %% Bonus: Generating the answer\n",
    "\n",
    "# Load Mistral api key and initialize the client\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "# Load environment variables from .env file and create Mistral client\n",
    "load_dotenv(dotenv_path='.env')\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model_small = \"mistral-small-latest\"\n",
    "\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "def llm(prompt):\n",
    "    # Generate the response\n",
    "    response = client.chat(\n",
    "        model=model_small,\n",
    "        messages=[ChatMessage(role=\"user\", content=prompt)]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_answer(query, results):\n",
    "    prompt = build_prompt(query, results)\n",
    "    answer = llm(prompt)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "print(f\"Question: {query}\\nAnswer: {generate_answer(query, results_filter)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
